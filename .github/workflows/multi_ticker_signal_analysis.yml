name: Multi-Ticker Signal Analysis

on:
  schedule:
    # Run every 2 hours during market hours (9:30 AM - 4:30 PM ET)
    - cron: '30 13,15,17,19,21 * * 1-5'  # 9:30, 11:30, 1:30, 3:30 PM ET
  workflow_dispatch:
    inputs:
      tickers:
        description: 'Comma-separated list of tickers (only those with historical data)'
        required: false
        default: 'auto'  # Will detect available tickers automatically
      force_run:
        description: 'Force run regardless of market hours'
        required: false
        default: 'false'
        type: boolean

env:
  PYTHONPATH: ${{ github.workspace }}
  TZ: America/New_York

jobs:
  detect-available-tickers:
    runs-on: ubuntu-latest
    outputs:
      tickers: ${{ steps.get_tickers.outputs.tickers }}
      ticker_count: ${{ steps.get_tickers.outputs.ticker_count }}
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up Python 3.9
      uses: actions/setup-python@v5
      with:
        python-version: '3.9'
        
    - name: Install Azure dependencies
      run: |
        pip install azure-storage-blob
      
    - name: Detect available tickers with historical data
      id: get_tickers
      env:
        STORAGE_ACCOUNT_NAME: ${{ secrets.STORAGE_ACCOUNT_NAME }}
        ACCESS_KEY: ${{ secrets.ACCESS_KEY }}
        CONTAINER_NAME: ${{ secrets.CONTAINER_NAME }}
      run: |
        python << 'EOF'
        import os
        import json
        from azure.storage.blob import BlobServiceClient
        
        # Initialize Azure client
        account_name = os.environ['STORAGE_ACCOUNT_NAME']
        access_key = os.environ['ACCESS_KEY']
        container_name = os.environ['CONTAINER_NAME']
        
        blob_service_client = BlobServiceClient(
            account_url=f"https://{account_name}.blob.core.windows.net",
            credential=access_key
        )
        container_client = blob_service_client.get_container_client(container_name)
        
        print("Detecting tickers with sufficient historical data from Azure...")
        
        AVAILABLE_TICKERS = []
        MIN_RECORDS = 2000  # Minimum records needed for effective pattern matching
        
        try:
            # Check the databento summary file first
            summary_blob = container_client.get_blob_client('databento/summary.json')
            summary_data = json.loads(summary_blob.download_blob().readall())
            
            # Check each ticker in the summary
            for ticker, info in summary_data.get('tickers', {}).items():
                record_count = info.get('total_records', 0)
                
                if record_count >= MIN_RECORDS:
                    print(f"✅ {ticker}: {record_count} records (sufficient)")
                    AVAILABLE_TICKERS.append(ticker)
                else:
                    print(f"⚠️  {ticker}: {record_count} records (insufficient, need {MIN_RECORDS}+)")
                    
        except Exception as e:
            print(f"Could not read summary file: {str(e)}")
            
            # Fallback: List all databento blobs
            print("Checking individual ticker files...")
            blobs = container_client.list_blobs(name_starts_with='databento/')
            
            for blob in blobs:
                if blob.name.endswith('_historical_data.json') and not blob.name.endswith('summary.json'):
                    ticker = blob.name.split('/')[-1].replace('_historical_data.json', '')
                    
                    try:
                        # Download and check record count
                        blob_client = container_client.get_blob_client(blob.name)
                        data = json.loads(blob_client.download_blob().readall())
                        
                        if 'metadata' in data:
                            record_count = data['metadata'].get('total_records', 0)
                        elif 'data' in data:
                            record_count = len(data['data'])
                        else:
                            record_count = len(data)
                        
                        if record_count >= MIN_RECORDS:
                            print(f"✅ {ticker}: {record_count} records (sufficient)")
                            AVAILABLE_TICKERS.append(ticker)
                        else:
                            print(f"⚠️  {ticker}: {record_count} records (insufficient, need {MIN_RECORDS}+)")
                            
                    except Exception as e:
                        print(f"Error checking {ticker}: {str(e)}")
        
        # Output the results
        if not AVAILABLE_TICKERS:
            print("❌ No tickers found with sufficient data in Azure")
            print("   Run 'Databento Historical Data Extraction' workflow first")
        
        # Write to GitHub output
        import subprocess
        tickers_json = json.dumps(AVAILABLE_TICKERS)
        with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
            f.write(f"tickers={tickers_json}\n")
            f.write(f"ticker_count={len(AVAILABLE_TICKERS)}\n")
        
        print(f"\nFinal ticker list: {AVAILABLE_TICKERS}")
        
        # Handle user input if provided
        user_input = "${{ github.event.inputs.tickers }}"
        if user_input and user_input != "auto":
            # User specified tickers, validate they have data
            user_tickers = [t.strip() for t in user_input.split(',')]
            valid_tickers = []
            
            for ticker in user_tickers:
                if ticker in AVAILABLE_TICKERS:
                    valid_tickers.append(ticker)
                else:
                    print(f"❌ {ticker}: Not available or insufficient data in Azure")
            
            # Update the output with validated user tickers
            if valid_tickers:
                tickers_json = json.dumps(valid_tickers)
                with open(os.environ['GITHUB_OUTPUT'], 'w') as f:
                    f.write(f"tickers={tickers_json}\n")
                    f.write(f"ticker_count={len(valid_tickers)}\n")
                print(f"Using user-specified tickers: {valid_tickers}")
        
        EOF

  multi-ticker-signal-analysis:
    needs: detect-available-tickers
    runs-on: ubuntu-latest
    timeout-minutes: 45
    strategy:
      matrix:
        ticker: ${{ fromJson(needs.detect-available-tickers.outputs.tickers) }}
      fail-fast: false
      max-parallel: 3
    if: needs.detect-available-tickers.outputs.ticker_count > 0
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up Python 3.9
      uses: actions/setup-python@v5
      with:
        python-version: '3.9'
        
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-signal-${{ hashFiles('**/requirements*.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-signal-
          ${{ runner.os }}-pip-
          
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install yfinance pandas numpy scikit-learn matplotlib mplfinance
        pip install azure-storage-blob python-dotenv pyyaml
        pip install ultralytics opencv-python-headless
        
    - name: Validate ticker has historical data
      id: check_ticker
      env:
        STORAGE_ACCOUNT_NAME: ${{ secrets.STORAGE_ACCOUNT_NAME }}
        ACCESS_KEY: ${{ secrets.ACCESS_KEY }}
        CONTAINER_NAME: ${{ secrets.CONTAINER_NAME }}
      run: |
        # Since the ticker passed the detection phase, we know it has data
        # This step is now just a confirmation
        TICKER="${{ matrix.ticker }}"
        echo "✅ $TICKER: Validated in Azure databento folder"
        echo "should_run=true" >> $GITHUB_OUTPUT
        
    - name: Check market hours
      id: market_hours
      if: steps.check_ticker.outputs.should_run == 'true'
      run: |
        python -c "
        import datetime
        import pytz
        
        et = pytz.timezone('US/Eastern')
        now = datetime.datetime.now(et)
        
        # Check if it's a weekday
        if now.weekday() >= 5:  # Saturday=5, Sunday=6
            print('Market closed: Weekend')
            exit(1)
            
        # Check market hours (9:30 AM - 4:00 PM ET)
        market_open = now.replace(hour=9, minute=30, second=0, microsecond=0)
        market_close = now.replace(hour=16, minute=0, second=0, microsecond=0)
        
        force_run = '${{ github.event.inputs.force_run }}' == 'true'
        
        if market_open <= now <= market_close or force_run:
            print(f'Market is open or force run enabled. Current time: {now.strftime(\"%Y-%m-%d %H:%M:%S %Z\")}')
        else:
            print(f'Market closed. Current time: {now.strftime(\"%Y-%m-%d %H:%M:%S %Z\")}')
            exit(1)
        "
        
    - name: Create environment file
      if: steps.check_ticker.outputs.should_run == 'true'
      run: |
        cat > .env << EOF
        STORAGE_ACCOUNT_NAME=${{ secrets.STORAGE_ACCOUNT_NAME }}
        ACCESS_KEY=${{ secrets.ACCESS_KEY }}
        CONTAINER_NAME=${{ secrets.CONTAINER_NAME }}
        GITHUB_TOKEN=${{ secrets.GITHUB_TOKEN }}
        TICKER=${{ matrix.ticker }}
        EOF
        
    - name: Generate signal predictions
      if: steps.check_ticker.outputs.should_run == 'true'
      run: |
        echo "Generating signal predictions for ${{ matrix.ticker }}"
        python scripts/generate_multi_ticker_predictions.py --ticker ${{ matrix.ticker }}
        
    - name: Evaluate recent predictions
      if: steps.check_ticker.outputs.should_run == 'true'
      continue-on-error: true
      run: |
        echo "Evaluating recent predictions for ${{ matrix.ticker }}"
        python scripts/evaluate_multi_ticker_predictions.py --ticker ${{ matrix.ticker }}
        
    - name: Upload logs as artifacts
      if: always() && steps.check_ticker.outputs.should_run == 'true'
      uses: actions/upload-artifact@v4
      with:
        name: signal-logs-${{ matrix.ticker }}-${{ github.run_number }}
        path: |
          logs/
          *.log
        retention-days: 7

  performance-summary:
    needs: multi-ticker-signal-analysis
    runs-on: ubuntu-latest
    if: always()
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up Python 3.9
      uses: actions/setup-python@v5
      with:
        python-version: '3.9'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install azure-storage-blob python-dotenv pandas numpy
        
    - name: Create environment file
      run: |
        cat > .env << EOF
        STORAGE_ACCOUNT_NAME=${{ secrets.STORAGE_ACCOUNT_NAME }}
        ACCESS_KEY=${{ secrets.ACCESS_KEY }}
        CONTAINER_NAME=${{ secrets.CONTAINER_NAME }}
        GITHUB_TOKEN=${{ secrets.GITHUB_TOKEN }}
        EOF
        
    - name: Generate performance summary
      continue-on-error: true
      run: |
        echo "Generating multi-ticker performance summary"
        python scripts/generate_performance_summary.py
        
    - name: Create GitHub issue for performance report
      continue-on-error: true
      run: |
        python scripts/create_performance_issue.py