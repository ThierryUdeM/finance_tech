name: Evaluate NVDA Pattern Predictions

on:
  schedule:
    # Run daily at 6 PM EST (11 PM UTC) after market close
    - cron: '0 23 * * *'
  workflow_dispatch:  # Allow manual trigger
  push:
    paths:
      - 'ChartScanAI_Shiny/evaluate_nvda_patterns.py'
      - 'directional_analysis/generate_nvda_predictions_simple.py'
      - '.github/workflows/evaluate_nvda_patterns.yml'

jobs:
  evaluate:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v3
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pandas numpy
        
    - name: Download NVDA data
      run: |
        # Create directory structure
        mkdir -p directional_analysis
        
        # Download NVDA data (you'll need to provide the actual data source)
        # For now, we'll assume the data is in the repository
        # In production, you might download from a data provider
        
        # If data is stored in repo (not recommended for large files)
        # cp data/NVDA_15min_pattern_ready.csv directional_analysis/
        
        # Or download from a secure source
        # curl -o directional_analysis/NVDA_15min_pattern_ready.csv ${{ secrets.DATA_URL }}
        
        echo "Data download step - implement based on your data source"
        
    - name: Run evaluation
      id: evaluate
      run: |
        cd ChartScanAI_Shiny
        python evaluate_nvda_patterns.py
        
        # Capture the exit code
        echo "::set-output name=exit_code::$?"
        
    - name: Upload evaluation results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: evaluation-results-${{ github.run_number }}
        path: |
          ChartScanAI_Shiny/evaluation_results/
          
    - name: Parse performance metrics
      if: always()
      run: |
        # Find the latest metrics file
        METRICS_FILE=$(ls -t ChartScanAI_Shiny/evaluation_results/nvda_metrics_*.json | head -1)
        
        if [ -f "$METRICS_FILE" ]; then
          echo "## Performance Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Extract metrics using Python
          python << EOF
        import json
        
        with open("$METRICS_FILE", 'r') as f:
            metrics = json.load(f)
        
        print("| Timeframe | Direction Accuracy | Avg Error | Predictions |")
        print("|-----------|-------------------|-----------|-------------|")
        
        for tf in ['1h', '3h', 'eod']:
            m = metrics[tf]
            print(f"| {tf.upper()} | {m['direction_accuracy']}% | {m['avg_error']}% | {m['total_predictions']} |")
        
        # Calculate overall accuracy
        overall = sum(metrics[tf]['direction_accuracy'] for tf in ['1h', '3h', 'eod']) / 3
        print(f"\n**Overall Direction Accuracy: {overall:.2f}%**")
        EOF
          
        fi >> $GITHUB_STEP_SUMMARY
        
    - name: Create issue if performance drops
      if: failure()
      uses: actions/github-script@v6
      with:
        script: |
          const issue = await github.rest.issues.create({
            owner: context.repo.owner,
            repo: context.repo.repo,
            title: 'NVDA Pattern Prediction Performance Below Threshold',
            body: `The NVDA pattern prediction evaluation failed the performance threshold.
            
            Check the [workflow run](${context.serverUrl}/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}) for details.
            
            This might indicate:
            - Changes in market behavior
            - Issues with the prediction algorithm
            - Data quality problems`,
            labels: ['performance', 'automated']
          });

  track-performance:
    needs: evaluate
    runs-on: ubuntu-latest
    if: always()
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v3
      
    - name: Download artifacts
      uses: actions/download-artifact@v3
      with:
        name: evaluation-results-${{ github.run_number }}
        path: ./evaluation_results
        
    - name: Update performance tracking
      run: |
        # Create performance history directory
        mkdir -p performance_history
        
        # Copy results to history with date
        DATE=$(date +%Y%m%d)
        cp -r evaluation_results/* performance_history/${DATE}_
        
        # Generate trend analysis (implement as needed)
        echo "Performance tracking updated"
        
    - name: Commit performance history
      uses: EndBug/add-and-commit@v9
      with:
        add: 'performance_history'
        message: 'Update NVDA pattern prediction performance history'
        default_author: github_actions