name: Evaluate NVDA Pattern Predictions

on:
  schedule:
    # Run daily at 6 PM EST (11 PM UTC) after market close
    - cron: '0 23 * * *'
  workflow_dispatch:  # Allow manual trigger
  push:
    paths:
      - 'ChartScanAI_Shiny/evaluate_nvda_patterns.py'
      - 'directional_analysis/generate_nvda_predictions_simple.py'
      - '.github/workflows/evaluate_nvda_patterns.yml'

jobs:
  evaluate:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      issues: write
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.9'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pandas numpy
        
    - name: Prepare NVDA data
      run: |
        # Create directory structure
        mkdir -p directional_analysis
        mkdir -p ChartScanAI_Shiny/evaluation_results
        
        # Step 1: Copy historical pattern library data (2.5 years for pattern matching)
        if [ -f "data/NVDA_15min_pattern_ready.csv" ]; then
          echo "✓ Using historical NVDA pattern library from repository"
          cp data/NVDA_15min_pattern_ready.csv directional_analysis/
          echo "Historical data stats:"
          wc -l directional_analysis/NVDA_15min_pattern_ready.csv
        else
          echo "✗ Historical pattern data not found at data/NVDA_15min_pattern_ready.csv"
          echo "The pattern matching system needs historical data to find similar patterns"
          exit 1
        fi
        
        # Step 2: Download current intraday data from yfinance
        echo ""
        echo "Downloading today's NVDA intraday data from yfinance..."
        pip install yfinance
        
        # Use the existing download script
        if [ -f "ChartScanAI_Shiny/download_intraday_data.py" ]; then
          python3 ChartScanAI_Shiny/download_intraday_data.py
        else
          echo "Download script not found, creating inline version..."
          python3 -c "
import yfinance as yf
import pandas as pd
from datetime import datetime, timedelta, time
import json
import os

# Download today's NVDA intraday data
ticker = yf.Ticker('NVDA')

# Get today's data (or last trading day if market is closed)
today = datetime.now()
if today.weekday() >= 5:  # Weekend
    # Go back to Friday
    days_back = today.weekday() - 4
    today = today - timedelta(days=days_back)

# Download 5 days to ensure we get the latest trading day
end_date = today + timedelta(days=1)
start_date = today - timedelta(days=5)

try:
    # Download intraday data
    intraday_data = ticker.history(start=start_date, end=end_date, interval='15m')
    
    if len(intraday_data) > 0:
        # Filter to get only today's data (last trading day)
        today_data = intraday_data[intraday_data.index.date == intraday_data.index.date[-1]]
        
        # Format for the evaluation system
        today_data.index.name = 'timestamp'
        today_data = today_data[['Open', 'High', 'Low', 'Close', 'Volume']]
        
        # Save today's data
        today_data.to_csv('directional_analysis/NVDA_intraday_current.csv')
        print(f'Downloaded {len(today_data)} bars of today\\'s NVDA data')
        print(f'Today\\'s data range: {today_data.index[0]} to {today_data.index[-1]}')
        print(f'Current price: ${today_data[\"Close\"].iloc[-1]:.2f}')
        
        # Save current state for predictions
        current_state = {
            'timestamp': str(today_data.index[-1]),
            'current_price': float(today_data['Close'].iloc[-1]),
            'bars_today': len(today_data),
            'market_open': str(today_data.index[0]),
            'last_update': str(datetime.now())
        }
        
        with open('directional_analysis/current_state.json', 'w') as f:
            json.dump(current_state, f, indent=2)
            
        # Also append today's completed bars to historical data
        # This keeps the pattern library up to date
        historical = pd.read_csv('directional_analysis/NVDA_15min_pattern_ready.csv', 
                                index_col='timestamp', parse_dates=True)
        
        # Get the last timestamp in historical data
        last_historical = historical.index[-1]
        
        # Only append bars that are after the last historical timestamp
        new_bars = today_data[today_data.index > last_historical]
        
        if len(new_bars) > 0:
            combined = pd.concat([historical, new_bars])
            combined.to_csv('directional_analysis/NVDA_15min_pattern_ready.csv')
            print(f'Added {len(new_bars)} new bars to historical data')
            print(f'Total historical bars: {len(combined)}')
        else:
            print('No new bars to add to historical data')
            
    else:
        print('Warning: Could not download intraday data from yfinance')
        
except Exception as e:
    print(f'Error downloading intraday data: {e}')
    print('Will proceed with existing data')
"
        fi
        
        # Verify data exists
        echo ""
        echo "Final data verification:"
        if [ -f "directional_analysis/NVDA_15min_pattern_ready.csv" ]; then
          echo "✓ NVDA pattern data ready"
          echo "Data preview:"
          head -5 directional_analysis/NVDA_15min_pattern_ready.csv
          tail -5 directional_analysis/NVDA_15min_pattern_ready.csv
          wc -l directional_analysis/NVDA_15min_pattern_ready.csv
        else
          echo "✗ Failed to prepare NVDA data"
          exit 1
        fi
        
    - name: Run evaluation
      id: evaluate
      run: |
        cd ChartScanAI_Shiny
        
        # Run the intraday evaluation (makes predictions and evaluates past ones)
        python evaluate_intraday_predictions.py
        
        # Store exit code
        EVAL_EXIT_CODE=$?
        
        # Also run the backtest evaluation for historical performance
        echo ""
        echo "Running historical backtest..."
        python evaluate_nvda_patterns.py || true
        
        # List contents to debug
        echo ""
        echo "Evaluation results:"
        ls -la evaluation_results/ || echo "No evaluation_results directory"
        
        # Use the intraday evaluation exit code
        echo "exit_code=${EVAL_EXIT_CODE}" >> $GITHUB_OUTPUT
        
    - name: Upload evaluation results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: evaluation-results-${{ github.run_number }}
        path: |
          ChartScanAI_Shiny/evaluation_results/
          
    - name: Parse performance metrics
      if: always()
      run: |
        # Find the latest metrics file
        METRICS_FILE=$(ls -t ChartScanAI_Shiny/evaluation_results/nvda_metrics_*.json | head -1)
        
        if [ -f "$METRICS_FILE" ]; then
          echo "## Performance Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Extract metrics using Python
          python << EOF
        import json
        
        with open("$METRICS_FILE", 'r') as f:
            metrics = json.load(f)
        
        print("| Timeframe | Direction Accuracy | Avg Error | Predictions |")
        print("|-----------|-------------------|-----------|-------------|")
        
        for tf in ['1h', '3h', 'eod']:
            m = metrics[tf]
            print(f"| {tf.upper()} | {m['direction_accuracy']}% | {m['avg_error']}% | {m['total_predictions']} |")
        
        # Calculate overall accuracy
        overall = sum(metrics[tf]['direction_accuracy'] for tf in ['1h', '3h', 'eod']) / 3
        print(f"\n**Overall Direction Accuracy: {overall:.2f}%**")
        EOF
          
        fi >> $GITHUB_STEP_SUMMARY
        
    - name: Create issue if performance drops
      if: failure()
      uses: actions/github-script@v6
      with:
        script: |
          const issue = await github.rest.issues.create({
            owner: context.repo.owner,
            repo: context.repo.repo,
            title: 'NVDA Pattern Prediction Performance Below Threshold',
            body: `The NVDA pattern prediction evaluation failed the performance threshold.
            
            Check the [workflow run](${context.serverUrl}/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}) for details.
            
            This might indicate:
            - Changes in market behavior
            - Issues with the prediction algorithm
            - Data quality problems`,
            labels: ['performance', 'automated']
          });

  track-performance:
    needs: evaluate
    runs-on: ubuntu-latest
    if: always()
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Download artifacts
      uses: actions/download-artifact@v4
      with:
        name: evaluation-results-${{ github.run_number }}
        path: ./evaluation_results
        
    - name: Update performance tracking
      run: |
        # Create performance history directory
        mkdir -p performance_history
        
        # Copy results to history with date
        DATE=$(date +%Y%m%d)
        cp -r evaluation_results/* performance_history/${DATE}_
        
        # Generate trend analysis (implement as needed)
        echo "Performance tracking updated"
        
    - name: Commit performance history
      uses: EndBug/add-and-commit@v9
      with:
        add: 'performance_history'
        message: 'Update NVDA pattern prediction performance history'
        default_author: github_actions