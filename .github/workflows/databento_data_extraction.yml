name: Databento Historical Data Extraction

on:
  workflow_dispatch:
    inputs:
      ticker:
        description: 'Ticker to extract data for (e.g., AAPL, MSFT, BTC-USD)'
        required: true
        type: string
      start_date:
        description: 'Start date (YYYY-MM-DD, default: 2.5 years ago)'
        required: false
        type: string
      end_date:
        description: 'End date (YYYY-MM-DD, default: today)'
        required: false
        type: string
      overwrite_existing:
        description: 'Overwrite existing data file'
        required: false
        default: false
        type: boolean

env:
  PYTHONPATH: ${{ github.workspace }}
  TZ: America/New_York

jobs:
  extract-databento-data:
    runs-on: ubuntu-latest
    timeout-minutes: 60
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up Python 3.9
      uses: actions/setup-python@v5
      with:
        python-version: '3.9'
        
    - name: Install databento and dependencies
      run: |
        python -m pip install --upgrade pip
        pip install databento pandas numpy pytz
        pip install azure-storage-blob
        
    - name: Validate ticker input
      run: |
        TICKER="${{ github.event.inputs.ticker }}"
        echo "Extracting data for ticker: $TICKER"
        
        # Validate ticker format
        if [[ ! "$TICKER" =~ ^[A-Z0-9.-]+$ ]]; then
          echo "Error: Invalid ticker format. Use uppercase letters, numbers, dots, and hyphens only."
          exit 1
        fi
        
        # Set default dates if not provided
        if [ -z "${{ github.event.inputs.start_date }}" ]; then
          # Default to 2.5 years ago (using Python for cross-platform compatibility)
          START_DATE=$(python -c "import datetime; print((datetime.datetime.now() - datetime.timedelta(days=912)).strftime('%Y-%m-%d'))")
        else
          START_DATE="${{ github.event.inputs.start_date }}"
        fi
        
        if [ -z "${{ github.event.inputs.end_date }}" ]; then
          END_DATE=$(python -c "import datetime; print(datetime.datetime.now().strftime('%Y-%m-%d'))")
        else
          END_DATE="${{ github.event.inputs.end_date }}"
        fi
        
        echo "TICKER=$TICKER" >> $GITHUB_ENV
        echo "START_DATE=$START_DATE" >> $GITHUB_ENV
        echo "END_DATE=$END_DATE" >> $GITHUB_ENV
        
        echo "Data extraction parameters:"
        echo "  Ticker: $TICKER"
        echo "  Start Date: $START_DATE"
        echo "  End Date: $END_DATE"
        
    - name: Check if data already exists
      id: check_data
      run: |
        DATA_FILE="data/${TICKER}_15min_pattern_ready.csv"
        if [ -f "$DATA_FILE" ] && [ "${{ github.event.inputs.overwrite_existing }}" != "true" ]; then
          echo "Data file already exists: $DATA_FILE"
          echo "Use overwrite_existing=true to replace it"
          echo "should_extract=false" >> $GITHUB_OUTPUT
        else
          echo "should_extract=true" >> $GITHUB_OUTPUT
        fi
        
    - name: Extract historical data from Databento
      if: steps.check_data.outputs.should_extract == 'true'
      env:
        DATABENTO_API_KEY: ${{ secrets.DATABENTO_API_KEY }}
        STORAGE_ACCOUNT_NAME: ${{ secrets.STORAGE_ACCOUNT_NAME }}
        ACCESS_KEY: ${{ secrets.ACCESS_KEY }}
        CONTAINER_NAME: ${{ secrets.CONTAINER_NAME }}
      run: |
        python << 'EOF'
        import os
        import pandas as pd
        import databento as db
        from datetime import datetime, timedelta
        import pytz
        
        # Configuration
        TICKER = os.environ['TICKER']
        START_DATE = os.environ['START_DATE']
        END_DATE = os.environ['END_DATE']
        
        print(f"Starting Databento extraction for {TICKER}")
        print(f"Date range: {START_DATE} to {END_DATE}")
        
        # Initialize Databento client
        client = db.Historical(key=os.environ['DATABENTO_API_KEY'])
        
        try:
            # Try multiple symbol variations for crypto
            if TICKER == 'BTC-USD':
                symbols_to_try = ['BTCUSD', 'BTC-USD', 'BTC.USD', 'XBTUSD']
                datasets_to_try = ['GLBX.MDP3', 'DBEQ.BASIC']
            else:
                # Map other tickers
                symbol_mapping = {
                    'AAPL': 'AAPL',
                    'MSFT': 'MSFT', 
                    'GOOGL': 'GOOGL',
                    'AMZN': 'AMZN',
                    'TSLA': 'TSLA',
                    'AC.TO': 'AC',
                    'SPY': 'SPY',
                    'QQQ': 'QQQ'
                }
                databento_symbol = symbol_mapping.get(TICKER, TICKER)
                symbols_to_try = [databento_symbol]
                
                # Determine dataset based on ticker
                if TICKER.endswith('.TO'):
                    datasets_to_try = ['XTOR.MDP3']
                else:
                    datasets_to_try = ['XNAS.ITCH', 'DBEQ.BASIC']
            
            print(f"Will try symbols: {symbols_to_try}")
            print(f"Will try datasets: {datasets_to_try}")
            
            # Try different combinations
            df = None
            for dataset in datasets_to_try:
                for symbol in symbols_to_try:
                    try:
                        print(f"Trying {dataset} with symbol {symbol}...")
                        
                        # Get data from Databento
                        bars = client.timeseries.get_range(
                            dataset=dataset,
                            symbols=[symbol],
                            schema='ohlcv-1m',
                            start=START_DATE,
                            end=END_DATE,
                            limit=200000
                        )
                        
                        # CRITICAL: Convert to DataFrame BEFORE checking empty
                        df = bars.to_df()
                        
                        if not df.empty:
                            print(f"✅ Success with {dataset} and symbol {symbol}")
                            print(f"Got {len(df)} records")
                            break
                        else:
                            print(f"No data for {dataset} with {symbol}")
                            
                    except Exception as e:
                        print(f"Failed {dataset} with {symbol}: {str(e)}")
                        continue
                
                if df is not None and not df.empty:
                    break
            
            # Check if we got any data
            if df is None or df.empty:
                print(f"No data returned for {TICKER} after trying all combinations.")
                print("This could be due to:")
                print("  - Invalid ticker symbol for Databento")
                print("  - Incorrect dataset selection")
                print("  - API key issues")
                print("  - Date range issues")
                exit(1)
            
            # Check available columns and adapt
            print(f"Available columns: {list(df.columns)}")
            
            # Find the timestamp column (could be ts_event, ts_recv, or index)
            timestamp_col = None
            if 'ts_event' in df.columns:
                timestamp_col = 'ts_event'
            elif 'ts_recv' in df.columns:
                timestamp_col = 'ts_recv'
            elif df.index.name and 'time' in df.index.name.lower():
                # Timestamp might be the index
                df.reset_index(inplace=True)
                timestamp_col = df.columns[0]
            else:
                # Try to find any column with 'time' in the name
                for col in df.columns:
                    if 'time' in col.lower() or 'ts' in col.lower():
                        timestamp_col = col
                        break
            
            if timestamp_col is None:
                # If no timestamp column found, assume index is timestamp
                df.reset_index(inplace=True)
                timestamp_col = 'index'
            
            print(f"Using timestamp column: {timestamp_col}")
            
            # Ensure we have OHLCV columns
            required_ohlcv = ['open', 'high', 'low', 'close', 'volume']
            missing_ohlcv = [col for col in required_ohlcv if col not in df.columns]
            if missing_ohlcv:
                print(f"Missing required OHLCV columns: {missing_ohlcv}")
                exit(1)
            
            # Resample 1-minute data to 15-minute intervals
            print("Resampling 1-minute data to 15-minute intervals...")
            df['timestamp'] = pd.to_datetime(df[timestamp_col])
            df.set_index('timestamp', inplace=True)
            
            # Resample to 15-minute intervals
            df_resampled = df.resample('15T').agg({
                'open': 'first',
                'high': 'max',
                'low': 'min', 
                'close': 'last',
                'volume': 'sum'
            }).dropna()
            
            # Reset index and use resampled data
            df_resampled.reset_index(inplace=True)
            df = df_resampled
            
            # Rename and format columns to match expected structure
            df_formatted = pd.DataFrame({
                'timestamp': df['timestamp'],
                'Open': df['open'].astype(float),
                'High': df['high'].astype(float), 
                'Low': df['low'].astype(float),
                'Close': df['close'].astype(float),
                'Volume': df['volume'].astype(int)
            })
            
            # Filter to regular trading hours (9:30 AM - 4:00 PM ET)
            et_tz = pytz.timezone('US/Eastern')
            
            # Handle timezone conversion
            if df_formatted['timestamp'].dt.tz is None:
                # If no timezone, assume UTC and convert to ET
                df_formatted['timestamp'] = df_formatted['timestamp'].dt.tz_localize('UTC').dt.tz_convert(et_tz)
            else:
                # If already has timezone, just convert to ET
                df_formatted['timestamp'] = df_formatted['timestamp'].dt.tz_convert(et_tz)
            
            # Filter for regular market hours (skip for crypto)
            if TICKER != 'BTC-USD':
                market_hours = (
                    (df_formatted['timestamp'].dt.hour > 9) |
                    ((df_formatted['timestamp'].dt.hour == 9) & (df_formatted['timestamp'].dt.minute >= 30))
                ) & (df_formatted['timestamp'].dt.hour < 16)
                
                # Filter for weekdays only
                weekdays = df_formatted['timestamp'].dt.weekday < 5
                df_filtered = df_formatted[market_hours & weekdays].copy()
            else:
                # For crypto, keep all hours
                df_filtered = df_formatted.copy()
            
            # Sort by timestamp
            df_filtered = df_filtered.sort_values('timestamp').reset_index(drop=True)
            
            print(f"Data extraction summary:")
            print(f"  Total records: {len(df_filtered):,}")
            print(f"  Date range: {df_filtered['timestamp'].min()} to {df_filtered['timestamp'].max()}")
            print(f"  Unique trading days: {df_filtered['timestamp'].dt.date.nunique()}")
            
            # Create data directory if it doesn't exist
            os.makedirs('data', exist_ok=True)
            
            # Save to CSV
            output_file = f'data/{TICKER}_15min_pattern_ready.csv'
            df_filtered.to_csv(output_file, index=False)
            
            print(f"Successfully saved data to {output_file}")
            
            # Validate minimum data requirements
            min_records_needed = 1000
            if len(df_filtered) < min_records_needed:
                print(f"WARNING: Only {len(df_filtered)} records extracted.")
                print(f"Signal model works best with {min_records_needed}+ records.")
            else:
                print(f"✅ Sufficient data extracted ({len(df_filtered)} records)")
                
        except Exception as e:
            print(f"Error during data extraction: {str(e)}")
            print("This could be due to:")
            print("  - Invalid ticker symbol for Databento")
            print("  - Incorrect dataset selection") 
            print("  - API key issues")
            print("  - Date range issues")
            exit(1)
        
        EOF
        
    - name: Commit data file to repository
      if: steps.check_data.outputs.should_extract == 'true'
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        
        DATA_FILE="data/${TICKER}_15min_pattern_ready.csv"
        
        if [ -f "$DATA_FILE" ]; then
          git add "$DATA_FILE"
          git commit -m "Add Databento historical data for ${TICKER}"
          git push
          echo "✅ Data file committed to repository"
        else
          echo "❌ Data file not found, commit skipped"
        fi