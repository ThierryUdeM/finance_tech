name: Reddit Sentiment Monitor

on:
  schedule:
    # Run every 4 hours
    - cron: '0 */4 * * *'
  workflow_dispatch:  # Allow manual trigger
    inputs:
      analysis_type:
        description: 'Type of analysis to run'
        required: false
        default: 'both'
        type: choice
        options:
          - scrape
          - analyze
          - both

env:
  R_VERSION: '4.3.3'

jobs:
  reddit-sentiment-scan:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Setup R
      uses: r-lib/actions/setup-r@v2
      with:
        r-version: ${{ env.R_VERSION }}
    
    - name: Cache R packages
      uses: actions/cache@v4
      with:
        path: ${{ env.R_LIBS_USER }}
        key: ${{ runner.os }}-r-${{ env.R_VERSION }}-${{ hashFiles('**/packages.txt') }}
        restore-keys: |
          ${{ runner.os }}-r-${{ env.R_VERSION }}-
    
    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y \
          libcurl4-openssl-dev \
          libssl-dev \
          libxml2-dev \
          libfontconfig1-dev \
          libharfbuzz-dev \
          libfribidi-dev
    
    - name: Install R packages
      run: |
        Rscript -e "install.packages('remotes', repos='https://cran.r-project.org')"
        Rscript -e "packages <- c('RedditExtractoR', 'dplyr', 'stringr', 'readr', 'lubridate', 'arrow', 'sentimentr', 'jsonlite', 'tibble', 'tidyr', 'ggplot2')"
        Rscript -e "for(pkg in packages) { if (!require(pkg, character.only = TRUE)) install.packages(pkg, repos='https://cran.r-project.org') }"
    
    - name: Download existing history from Azure (if exists)
      env:
        AZURE_STORAGE_ACCOUNT: ${{ secrets.STORAGE_ACCOUNT_NAME }}
        AZURE_STORAGE_KEY: ${{ secrets.ACCESS_KEY }}
        AZURE_CONTAINER: ${{ secrets.CONTAINER_NAME }}
      run: |
        # Install Azure CLI
        curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash
        
        # Create data directories
        mkdir -p data/traction/history
        
        # Download existing history files if they exist
        echo "Downloading existing history from Azure..."
        
        # Download valid tickers cache
        az storage blob download \
          --account-name "$AZURE_STORAGE_ACCOUNT" \
          --account-key "$AZURE_STORAGE_KEY" \
          --container-name "$AZURE_CONTAINER" \
          --name "reddit_sentiment/valid_tickers.rds" \
          --file "data/traction/valid_tickers.rds" \
          --no-progress 2>/dev/null || echo "No existing ticker cache"
        
        # Download master history
        az storage blob download \
          --account-name "$AZURE_STORAGE_ACCOUNT" \
          --account-key "$AZURE_STORAGE_KEY" \
          --container-name "$AZURE_CONTAINER" \
          --name "reddit_sentiment/history/master_history.csv" \
          --file "data/traction/history/master_history.csv" \
          --no-progress 2>/dev/null || echo "No existing history"
        
        # Download recent mention files (last 7 days)
        for i in {0..6}; do
          DATE=$(date -d "$i days ago" +%Y%m%d)
          az storage blob list \
            --account-name "$AZURE_STORAGE_ACCOUNT" \
            --account-key "$AZURE_STORAGE_KEY" \
            --container-name "$AZURE_CONTAINER" \
            --prefix "reddit_sentiment/history/mentions_${DATE}" \
            --output tsv --query "[].name" | while read blob; do
            if [ ! -z "$blob" ]; then
              filename=$(basename "$blob")
              az storage blob download \
                --account-name "$AZURE_STORAGE_ACCOUNT" \
                --account-key "$AZURE_STORAGE_KEY" \
                --container-name "$AZURE_CONTAINER" \
                --name "$blob" \
                --file "data/traction/history/$filename" \
                --no-progress || true
            fi
          done
        done
        
        echo "Download complete. Files in history:"
        ls -la data/traction/history/ || true
    
    - name: Run Reddit Sentiment Scanner
      run: |
        echo "Running Reddit sentiment scanner..."
        
        # Default to 'both' if not specified
        ANALYSIS_TYPE="${{ github.event.inputs.analysis_type || 'both' }}"
        
        if [ "$ANALYSIS_TYPE" = "scrape" ] || [ "$ANALYSIS_TYPE" = "both" ]; then
          echo "=== Running Scraper ==="
          timeout 300 Rscript reddit_sentiment_strict.R || {
            echo "Scraper timeout or error, continuing..."
          }
          
          # Save timestamped copy
          if [ -f "data/traction/reddit_mentions_strict.csv" ]; then
            TIMESTAMP=$(date +%Y%m%d_%H%M%S)
            cp data/traction/reddit_mentions_strict.csv "data/traction/history/mentions_${TIMESTAMP}.csv"
            
            # Append to master history
            if [ -f "data/traction/history/master_history.csv" ]; then
              tail -n +2 data/traction/reddit_mentions_strict.csv | \
              awk -v ts="$(date -Iseconds)" -F',' '{print $0","ts}' >> data/traction/history/master_history.csv
            else
              echo "ticker,mentions,posts,comments,subreddits,timestamp" > data/traction/history/master_history.csv
              tail -n +2 data/traction/reddit_mentions_strict.csv | \
              awk -v ts="$(date -Iseconds)" -F',' '{print $0","ts}' >> data/traction/history/master_history.csv
            fi
          fi
        fi
        
        if [ "$ANALYSIS_TYPE" = "analyze" ] || [ "$ANALYSIS_TYPE" = "both" ]; then
          echo "=== Running Analysis ==="
          # Check if we have enough history
          HISTORY_COUNT=$(find data/traction/history -name "mentions_*.csv" 2>/dev/null | wc -l)
          echo "Found $HISTORY_COUNT historical data points"
          
          if [ "$HISTORY_COUNT" -ge 3 ]; then
            Rscript reddit_trend_analyzer.R analyze || echo "Analysis completed with warnings"
          else
            echo "Need at least 3 data points for trend analysis (current: $HISTORY_COUNT)"
          fi
        fi
        
        echo "=== Current Top Stocks ==="
        if [ -f "data/traction/reddit_mentions_strict.csv" ]; then
          head -20 data/traction/reddit_mentions_strict.csv
        fi
    
    - name: Generate Summary Report
      run: |
        TIMESTAMP=$(date +%Y%m%d_%H%M%S)
        REPORT_FILE="data/traction/github_report_${TIMESTAMP}.txt"
        
        echo "Reddit Sentiment Report - $(date)" > $REPORT_FILE
        echo "======================================" >> $REPORT_FILE
        echo "" >> $REPORT_FILE
        
        if [ -f "data/traction/reddit_mentions_strict.csv" ]; then
          echo "TOP MENTIONED STOCKS:" >> $REPORT_FILE
          echo "--------------------" >> $REPORT_FILE
          head -20 data/traction/reddit_mentions_strict.csv | column -t -s',' >> $REPORT_FILE
          echo "" >> $REPORT_FILE
        fi
        
        if [ -f "data/traction/trend_analysis_latest.csv" ]; then
          echo "" >> $REPORT_FILE
          echo "TREND ANALYSIS:" >> $REPORT_FILE
          echo "--------------" >> $REPORT_FILE
          head -20 data/traction/trend_analysis_latest.csv | column -t -s',' >> $REPORT_FILE
        fi
        
        echo "" >> $REPORT_FILE
        echo "Generated at: $(date)" >> $REPORT_FILE
        echo "Workflow run: ${{ github.run_number }}" >> $REPORT_FILE
        
        cat $REPORT_FILE
    
    - name: Upload to Azure Storage
      env:
        AZURE_STORAGE_ACCOUNT: ${{ secrets.STORAGE_ACCOUNT_NAME }}
        AZURE_STORAGE_KEY: ${{ secrets.ACCESS_KEY }}
        AZURE_CONTAINER: ${{ secrets.CONTAINER_NAME }}
      run: |
        echo "Uploading results to Azure Storage..."
        
        TIMESTAMP=$(date +%Y%m%d_%H%M%S)
        
        # Upload current snapshot
        if [ -f "data/traction/reddit_mentions_strict.csv" ]; then
          az storage blob upload \
            --account-name "$AZURE_STORAGE_ACCOUNT" \
            --account-key "$AZURE_STORAGE_KEY" \
            --container-name "$AZURE_CONTAINER" \
            --name "reddit_sentiment/latest/reddit_mentions_latest.csv" \
            --file "data/traction/reddit_mentions_strict.csv" \
            --overwrite \
            --no-progress
          
          # Also save timestamped version
          az storage blob upload \
            --account-name "$AZURE_STORAGE_ACCOUNT" \
            --account-key "$AZURE_STORAGE_KEY" \
            --container-name "$AZURE_CONTAINER" \
            --name "reddit_sentiment/history/mentions_${TIMESTAMP}.csv" \
            --file "data/traction/reddit_mentions_strict.csv" \
            --no-progress
        fi
        
        # Upload trend analysis
        if [ -f "data/traction/trend_analysis_latest.csv" ]; then
          az storage blob upload \
            --account-name "$AZURE_STORAGE_ACCOUNT" \
            --account-key "$AZURE_STORAGE_KEY" \
            --container-name "$AZURE_CONTAINER" \
            --name "reddit_sentiment/latest/trend_analysis_latest.csv" \
            --file "data/traction/trend_analysis_latest.csv" \
            --overwrite \
            --no-progress
        fi
        
        # Upload master history
        if [ -f "data/traction/history/master_history.csv" ]; then
          az storage blob upload \
            --account-name "$AZURE_STORAGE_ACCOUNT" \
            --account-key "$AZURE_STORAGE_KEY" \
            --container-name "$AZURE_CONTAINER" \
            --name "reddit_sentiment/history/master_history.csv" \
            --file "data/traction/history/master_history.csv" \
            --overwrite \
            --no-progress
        fi
        
        # Upload ticker cache
        if [ -f "data/traction/valid_tickers.rds" ]; then
          az storage blob upload \
            --account-name "$AZURE_STORAGE_ACCOUNT" \
            --account-key "$AZURE_STORAGE_KEY" \
            --container-name "$AZURE_CONTAINER" \
            --name "reddit_sentiment/valid_tickers.rds" \
            --file "data/traction/valid_tickers.rds" \
            --overwrite \
            --no-progress
        fi
        
        # Upload reports
        for report in data/traction/*.txt; do
          if [ -f "$report" ]; then
            filename=$(basename "$report")
            az storage blob upload \
              --account-name "$AZURE_STORAGE_ACCOUNT" \
              --account-key "$AZURE_STORAGE_KEY" \
              --container-name "$AZURE_CONTAINER" \
              --name "reddit_sentiment/reports/$filename" \
              --file "$report" \
              --no-progress
          fi
        done
        
        echo "âœ… Upload complete!"
        echo ""
        echo "Files uploaded to Azure container: $AZURE_CONTAINER"
        echo "Path: reddit_sentiment/"
        echo ""
        echo "Latest files:"
        az storage blob list \
          --account-name "$AZURE_STORAGE_ACCOUNT" \
          --account-key "$AZURE_STORAGE_KEY" \
          --container-name "$AZURE_CONTAINER" \
          --prefix "reddit_sentiment/latest/" \
          --output table
    
    - name: Create Summary Issue (if significant changes)
      if: github.event_name == 'schedule'
      env:
        GH_TOKEN: ${{ github.token }}
      run: |
        # Check if we found new trending stocks
        if [ -f "data/traction/reddit_mentions_strict.csv" ]; then
          # Get top 5 stocks
          TOP_STOCKS=$(head -6 data/traction/reddit_mentions_strict.csv | tail -5 | cut -d',' -f1 | paste -sd', ')
          
          # Check for high momentum stocks (customize threshold as needed)
          HIGH_MOMENTUM=$(awk -F',' 'NR>1 && $2>10 {print $1}' data/traction/reddit_mentions_strict.csv | head -3 | paste -sd', ')
          
          if [ ! -z "$HIGH_MOMENTUM" ]; then
            TITLE="ðŸš¨ Reddit Sentiment Alert: High momentum detected for $HIGH_MOMENTUM"
            
            # Create the body content
            BODY="## Reddit Sentiment Analysis - $(date '+%Y-%m-%d %H:%M')
        
        ### Top Trending Stocks
        $TOP_STOCKS
        
        ### High Momentum Detected
        The following stocks show significant Reddit activity:
        $HIGH_MOMENTUM
        
        ### View Full Report
        Check the Azure container for detailed analysis:
        - Container: ${{ secrets.CONTAINER_NAME }}
        - Path: reddit_sentiment/latest/
        
        ### Next Steps
        1. Review the trending stocks
        2. Check actual stock prices for these tickers
        3. Read the Reddit posts for context
        4. Consider adding to watchlist
        
        ---
        *This alert was automatically generated by the Reddit Sentiment Monitor workflow*"
            
            # Create issue only if it doesn't exist
            EXISTING=$(gh issue list --label "reddit-sentiment" --state open --limit 1 --json number --jq '.[0].number')
            
            if [ -z "$EXISTING" ]; then
              gh issue create \
                --title "$TITLE" \
                --body "$BODY" \
                --label "reddit-sentiment,automated"
            else
              # Update existing issue with comment
              gh issue comment $EXISTING --body "## Update - $(date '+%Y-%m-%d %H:%M')
        
        Latest trending: $TOP_STOCKS"
            fi
          fi
        fi
    
    - name: Upload artifacts
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: reddit-sentiment-results-${{ github.run_number }}
        path: |
          data/traction/*.csv
          data/traction/*.txt
          data/traction/history/*.csv
        retention-days: 30